{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962a16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070543c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw DataFrame:\n",
      "         barcode                        name  \\\n",
      "0  0044000004464                Oreo Cookies   \n",
      "1   078742300512    Jif Creamy Peanut Butter   \n",
      "2   041196912573     Nutella Hazelnut Spread   \n",
      "3   030000016042  Lay's Classic Potato Chips   \n",
      "4   028400076053        Doritos Nacho Cheese   \n",
      "\n",
      "                                         ingredients          allergens  \n",
      "0  [Sugar, Palm Oil, Cocoa, Wheat Flour, Soy Leci...       [Wheat, Soy]  \n",
      "1                     [Roasted Peanuts, Sugar, Salt]             [Nuts]  \n",
      "2  [Sugar, Palm Oil, Hazelnuts, Cocoa, Milk, Soy ...  [Nuts, Milk, Soy]  \n",
      "3                    [Potatoes, Vegetable Oil, Salt]                 []  \n",
      "4  [Corn, Vegetable Oil, Cheese, Milk, Salt, Garl...             [Milk]  \n"
     ]
    }
   ],
   "source": [
    "with open('products.json') as f:\n",
    "    products = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(products)\n",
    "print(\"Raw DataFrame:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba42ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name          allergens  \\\n",
      "0                Oreo Cookies       [wheat, soy]   \n",
      "1    Jif Creamy Peanut Butter             [nuts]   \n",
      "2     Nutella Hazelnut Spread  [nuts, milk, soy]   \n",
      "3  Lay's Classic Potato Chips                 []   \n",
      "4        Doritos Nacho Cheese             [milk]   \n",
      "\n",
      "                                   combined_features  \n",
      "0  oreo cookies sugar palm oil cocoa wheat flour ...  \n",
      "1  jif creamy peanut butter roasted peanuts sugar...  \n",
      "2  nutella hazelnut spread sugar palm oil hazelnu...  \n",
      "3  lay's classic potato chips potatoes vegetable ...  \n",
      "4  doritos nacho cheese corn vegetable oil cheese...  \n"
     ]
    }
   ],
   "source": [
    "df['combined_features'] = df['name'] + ' ' + df['ingredients'].apply(' '.join)\n",
    "df['combined_features'] = df['combined_features'].str.lower()\n",
    "\n",
    "# Convert allergens to consistent format\n",
    "df['allergens'] = df['allergens'].apply(lambda x: [a.lower().strip() for a in x])\n",
    "\n",
    "print(\"\\nProcessed DataFrame:\")\n",
    "print(df[['name', 'allergens', 'combined_features']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a490a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained TF-IDF model with 137 features\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(df['combined_features'])\n",
    "print(f\"\\nTrained TF-IDF model with {len(vectorizer.vocabulary_)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b80a13e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AllergyRecommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m safe_df\u001b[38;5;241m.\u001b[39mhead(top_n)\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Initialize recommender\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m recommender \u001b[38;5;241m=\u001b[39m \u001b[43mAllergyRecommender\u001b[49m(df, vectorizer, tfidf_matrix)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AllergyRecommender' is not defined"
     ]
    }
   ],
   "source": [
    "def get_recommendations(self, scanned_text, user_allergies, top_n=3):\n",
    "        # Filter safe products using pandas\n",
    "        user_allergies = [a.lower().strip() for a in user_allergies]\n",
    "        \n",
    "        # Create allergen mask\n",
    "        safe_mask = ~self.df['allergens'].apply(\n",
    "            lambda x: any(allergy in x for allergy in user_allergies)\n",
    "        )\n",
    "        \n",
    "        safe_df = self.df[safe_mask].copy()\n",
    "        \n",
    "        if safe_df.empty:\n",
    "            return []\n",
    "        \n",
    "        # Vectorize input text\n",
    "        input_vector = self.vectorizer.transform([scanned_text.lower()])\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = cosine_similarity(input_vector, self.tfidf_matrix[safe_df.index])\n",
    "        safe_df['similarity_score'] = similarities[0]\n",
    "        \n",
    "        # Filter and sort\n",
    "        safe_df = safe_df[safe_df['similarity_score'] > 0]\n",
    "        safe_df = safe_df.sort_values('similarity_score', ascending=False)\n",
    "        \n",
    "        return safe_df.head(top_n).to_dict('records')\n",
    "\n",
    "# Initialize recommender\n",
    "recommender = AllergyRecommender(df, vectorizer, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19f121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "1. Safety Accuracy: 100.00%\n",
      "2. Precision@1: 62.90%\n",
      "3. Precision@3: 62.90%\n",
      "4. Coverage: 67.74%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, df, recommender):\n",
    "        self.df = df\n",
    "        self.recommender = recommender\n",
    "        self.results = []\n",
    "    \n",
    "    def generate_test_cases(self, test_size=0.2):\n",
    "        \"\"\"Create synthetic test cases from existing data\"\"\"\n",
    "        # Use products with allergens as test cases\n",
    "        allergic_products = self.df[self.df['allergens'].apply(len) > 0]\n",
    "        self.test_cases = []\n",
    "        \n",
    "        for _, row in allergic_products.iterrows():\n",
    "            self.test_cases.append({\n",
    "                'scanned_text': row['name'],\n",
    "                'user_allergies': row['allergens'],\n",
    "                'expected_allergen_free': True,\n",
    "                'expected_similar_product': row['name']  # Ideally should find alternative\n",
    "            })\n",
    "            \n",
    "        # Add some safe product tests\n",
    "        safe_products = self.df[self.df['allergens'].apply(len) == 0]\n",
    "        for _, row in safe_products.sample(min(5, len(safe_products))).iterrows():\n",
    "            self.test_cases.append({\n",
    "                'scanned_text': row['name'],\n",
    "                'user_allergies': [],\n",
    "                'expected_allergen_free': True,\n",
    "                'expected_similar_product': row['name']\n",
    "            })\n",
    "        \n",
    "        return self.test_cases\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Run evaluation metrics\"\"\"\n",
    "        metrics = {\n",
    "            'precision@1': 0,\n",
    "            'precision@3': 0,\n",
    "            'safety_accuracy': 0,\n",
    "            'coverage': 0\n",
    "        }\n",
    "        \n",
    "        valid_tests = 0\n",
    "        \n",
    "        for case in self.test_cases:\n",
    "            recommendations = self.recommender.get_recommendations(\n",
    "                case['scanned_text'],\n",
    "                case['user_allergies'],\n",
    "                top_n=3\n",
    "            )\n",
    "            \n",
    "            # Safety Check\n",
    "            safe = all(\n",
    "                not any(allergy in rec['allergens'] \n",
    "                    for allergy in case['user_allergies'])\n",
    "                for rec in recommendations\n",
    "            )\n",
    "            metrics['safety_accuracy'] += safe\n",
    "            \n",
    "            # Precision Checks\n",
    "            relevant = 0\n",
    "            for rec in recommendations:\n",
    "                if self._is_relevant(rec, case['scanned_text']):\n",
    "                    relevant += 1\n",
    "            \n",
    "            if recommendations:\n",
    "                metrics['precision@1'] += (relevant >= 1)\n",
    "                metrics['precision@3'] += (relevant >= 1)  # At least 1 relevant\n",
    "                metrics['coverage'] += 1\n",
    "            \n",
    "            valid_tests += 1\n",
    "        \n",
    "        # Normalize metrics\n",
    "        for k in metrics:\n",
    "            metrics[k] = metrics[k] / valid_tests if valid_tests > 0 else 0\n",
    "            \n",
    "        return metrics\n",
    "    \n",
    "    def _is_relevant(self, recommendation, query):\n",
    "        \"\"\"Custom relevance criteria (adjust based on your domain)\"\"\"\n",
    "        query_terms = set(query.lower().split())\n",
    "        product_terms = set(recommendation['name'].lower().split())\n",
    "        return len(query_terms & product_terms) > 0\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Run Evaluation\n",
    "# %%\n",
    "evaluator = ModelEvaluator(df, recommender)\n",
    "test_cases = evaluator.generate_test_cases()\n",
    "metrics = evaluator.evaluate()\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"1. Safety Accuracy: {metrics['safety_accuracy']:.2%}\")\n",
    "print(f\"2. Precision@1: {metrics['precision@1']:.2%}\")\n",
    "print(f\"3. Precision@3: {metrics['precision@3']:.2%}\")\n",
    "print(f\"4. Coverage: {metrics['coverage']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fef3ac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚨 Testing Product: Macadamia Nuts\n",
      "   Barcode: 0009876543218\n",
      "   Allergens: Nuts\n",
      "   ✅ Recommended Alternatives:\n",
      "   1. Mixed Nuts (Score: 0.27)\n",
      "      Allergens: Nuts\n",
      "   2. Hershey's Nuts Chocolate Bar (Score: 0.21)\n",
      "      Allergens: Milk, Soy, Nuts\n",
      "   3. Peanut Butter (Score: 0.05)\n",
      "      Allergens: Nuts\n",
      "\n",
      "🚨 Testing Product: Kit Kat Chocolate Bar\n",
      "   Barcode: 050000000412\n",
      "   Allergens: Milk, Soy\n",
      "   ✅ Recommended Alternatives:\n",
      "   1. Hershey's Milk  Chocolate Bar (Score: 0.74)\n",
      "      Allergens: Milk, Soy\n",
      "   2. Milk Chocolate Bar (Score: 0.71)\n",
      "      Allergens: Milk\n",
      "   3. Hershey's Nuts Chocolate Bar (Score: 0.69)\n",
      "      Allergens: Milk, Soy, Nuts\n",
      "\n",
      "🚨 Testing Product: Coconut Cookies\n",
      "   Barcode: 0054321876543\n",
      "   Allergens: Eggs\n",
      "   ✅ Recommended Alternatives:\n",
      "   1. Juhayna Coconut Yogurt (Score: 0.57)\n",
      "      Allergens: None\n",
      "   2. Coconut Almond Granola (Score: 0.53)\n",
      "      Allergens: Nuts, Wheat\n",
      "   3. Coconut Secret Aminos (Imported) (Score: 0.51)\n",
      "      Allergens: None\n",
      "\n",
      "🚨 Testing Product: Coconut Almond Granola\n",
      "   Barcode: 0052109876543\n",
      "   Allergens: Nuts, Wheat\n",
      "   ✅ Recommended Alternatives:\n",
      "   1. Coconut Cookies (Score: 0.53)\n",
      "      Allergens: Eggs\n",
      "   2. Juhayna Coconut Yogurt (Score: 0.45)\n",
      "      Allergens: None\n",
      "   3. Coconut Secret Aminos (Imported) (Score: 0.41)\n",
      "      Allergens: None\n",
      "\n",
      "🚨 Testing Product: Campbell's Tomato Soup\n",
      "   Barcode: 023100104576\n",
      "   Allergens: Wheat\n",
      "   ✅ Recommended Alternatives:\n",
      "   1. Whole Wheat Bread (Score: 0.30)\n",
      "      Allergens: Wheat\n",
      "   2. Sweet Corn Soup (Score: 0.27)\n",
      "      Allergens: Milk\n",
      "   3. Edita Tiger Biscuits (Wheat) (Score: 0.18)\n",
      "      Allergens: Wheat\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Random Product Test\n",
    "# %%\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load products\n",
    "with open('products.json') as f:\n",
    "    all_products = json.load(f)\n",
    "\n",
    "# Randomly select 5 test products\n",
    "test_products = random.sample(all_products, 5)\n",
    "\n",
    "# Create combined text features (name + ingredients)\n",
    "product_texts = [\n",
    "    f\"{p['name']} {' '.join(p['ingredients'])}\".lower() \n",
    "    for p in all_products\n",
    "]\n",
    "\n",
    "# Train TF-IDF model\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(product_texts)\n",
    "\n",
    "# Test each random product\n",
    "for product in test_products:\n",
    "    print(f\"\\n🚨 Testing Product: {product['name']}\")\n",
    "    print(f\"   Barcode: {product['barcode']}\")\n",
    "    print(f\"   Allergens: {', '.join(product['allergens']) or 'None'}\")\n",
    "    \n",
    "    # Assume user has these allergies\n",
    "    user_allergies = [a.lower() for a in product['allergens']]\n",
    "    \n",
    "    # Find safe alternatives (exclude current product)\n",
    "    safe_products = [\n",
    "        p for p in all_products \n",
    "        if not any(a in p['allergens'] for a in user_allergies)\n",
    "        and p['barcode'] != product['barcode']\n",
    "    ]\n",
    "    \n",
    "    if not safe_products:\n",
    "        print(\"   ❌ No safe alternatives found\")\n",
    "        continue\n",
    "    \n",
    "    # Get similarity scores\n",
    "    product_idx = all_products.index(product)\n",
    "    safe_indices = [all_products.index(p) for p in safe_products]\n",
    "    similarities = cosine_similarity(tfidf_matrix[product_idx], tfidf_matrix[safe_indices])[0]\n",
    "    \n",
    "    # Get top 3 matches\n",
    "    top_matches = np.argsort(similarities)[::-1][:3]\n",
    "    \n",
    "    print(\"   ✅ Recommended Alternatives:\")\n",
    "    for i, idx in enumerate(top_matches, 1):\n",
    "        match = safe_products[idx]\n",
    "        score = similarities[idx]\n",
    "        print(f\"   {i}. {match['name']} (Score: {score:.2f})\")\n",
    "        print(f\"      Allergens: {', '.join(match['allergens']) or 'None'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
